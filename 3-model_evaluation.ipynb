{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprocessing import generate_tasks\n",
    "from fitting import get_model, evaluate\n",
    "from meta import Meta\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename and name\n",
    "name = \"K100Q200-HL4-F112F90F95F33\"\n",
    "filename = \"models/\" + name + \".pt\"\n",
    "hidden_layers = [112, 90, 95, 33]\n",
    "\n",
    "# Arguments to create model\n",
    "meta_lr = 1e-3\n",
    "sup_shots = 100\n",
    "que_shots = 200\n",
    "lr_type = \"vector\"\n",
    "inner_lr = 1e-2\n",
    "\n",
    "# Choose PyTorch device and load the model\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = Meta(name, meta_lr, sup_shots, que_shots, lr_type, \n",
    "             inner_lr, get_model(hidden_layers), device).to(device)\n",
    "model.load_params(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "# Datapath and background file for data-files\n",
    "datapath = \"processed-data/\"\n",
    "bkg_file = datapath + \"bkg.h5\"\n",
    "\n",
    "# Signal files for each task split\n",
    "val_signals = [\"hg3000_hq1200\", \"wohg_hq1000\"]\n",
    "test_signals = [\"wohg_hq1400\", \"fcnc\"]\n",
    "\n",
    "# Add datapath and extention to files for each split\n",
    "val_signals = [datapath + p + \".h5\" for p in val_signals]\n",
    "test_signals = [datapath + p + \".h5\" for p in test_signals]\n",
    "\n",
    "# Generate tasks\n",
    "val_tasks = generate_tasks(val_signals, bkg_file, args[\"k_sup\"], args[\"k_que\"])\n",
    "test_tasks = generate_tasks(test_signals, bkg_file, args[\"k_sup\"], args[\"k_que\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on the val and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, val_tasks, 200, \"Eval Val\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
