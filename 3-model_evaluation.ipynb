{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from fitting import get_model, get_model_name, evaluate\n",
    "from dataprocessing import generate_tasks\n",
    "from meta import get_class_weights, Meta\n",
    "import numpy as np\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Model architecture\n",
    "hidden_layers = [85, 91]\n",
    "\n",
    "# Arguments to create model\n",
    "sup_shots = 100\n",
    "que_shots = 200\n",
    "dropout = 0.07\n",
    "name = get_model_name(sup_shots, que_shots, dropout, hidden_layers)\n",
    "config = get_model(hidden_layers, dropout)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Model filename\n",
    "filename = \"models/\" + name + \".pt\"\n",
    "\n",
    "# Choose PyTorch device and load the model\n",
    "model = Meta(name, config, sup_shots, que_shots, device).to(device)\n",
    "model.load(filename)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Datapath and background file for data-files\n",
    "datapath = \"processed-data/\"\n",
    "bkg_file = datapath + \"bkg.h5\"\n",
    "\n",
    "# Signal files for each task split\n",
    "val_signals = [\"hg3000_hq1200\", \"wohg_hq1000\"]\n",
    "test_signals = [\"wohg_hq1400\", \"fcnc\"]\n",
    "\n",
    "# Add datapath and extention to files for each split\n",
    "val_signals = [datapath + p + \".h5\" for p in val_signals]\n",
    "test_signals = [datapath + p + \".h5\" for p in test_signals]\n",
    "\n",
    "# Generate tasks\n",
    "sup_shots = 100\n",
    "que_shots = 200\n",
    "val_tasks = generate_tasks(val_signals, bkg_file, sup_shots, que_shots)\n",
    "test_tasks = generate_tasks(test_signals, bkg_file, sup_shots, que_shots)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate on the val and test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\n",
    "# evaluate(model, val_tasks, 200, \"Eval Val\")\n",
    "\n",
    "# Get support sample\n",
    "x_sup, w_sup, y_sup = next(test_tasks[\"fcnc\"][\"sup\"][\"data\"])\n",
    "class_weights = get_class_weights(test_tasks[\"fcnc\"][\"sup\"][\"weights\"], y_sup)\n",
    "\n",
    "# Get query sample to predict on\n",
    "x_que, w_que, y_que = next(test_tasks[\"fcnc\"][\"que\"][\"data\"])\n",
    "y_hat = model.predict(x_sup, w_sup, y_sup, x_que, class_weights)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f5ff148e73835ca4fa28de0f0a60b6e4be9e22106b47c94548bad0fe3aa25f7"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('DeepLearning': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}