{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fitting import get_model, get_model_name, evaluate\n",
    "from dataprocessing import generate_tasks\n",
    "from meta import Meta\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "hidden_layers = [112, 90, 95, 33]\n",
    "\n",
    "# Arguments to create model\n",
    "sup_shots = 100\n",
    "que_shots = 200\n",
    "name = get_model_name(sup_shots, que_shots, hidden_layers)\n",
    "config = get_model(hidden_layers)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Model filename\n",
    "filename = \"models/\" + name + \".pt\"\n",
    "\n",
    "# Choose PyTorch device and load the model\n",
    "model = Meta(name, config, sup_shots, que_shots, device).to(device)\n",
    "model.load_params(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "# Datapath and background file for data-files\n",
    "datapath = \"processed-data/\"\n",
    "bkg_file = datapath + \"bkg.h5\"\n",
    "\n",
    "# Signal files for each task split\n",
    "val_signals = [\"hg3000_hq1200\", \"wohg_hq1000\"]\n",
    "test_signals = [\"wohg_hq1400\", \"fcnc\"]\n",
    "\n",
    "# Add datapath and extention to files for each split\n",
    "val_signals = [datapath + p + \".h5\" for p in val_signals]\n",
    "test_signals = [datapath + p + \".h5\" for p in test_signals]\n",
    "\n",
    "# Generate tasks\n",
    "val_tasks = generate_tasks(val_signals, bkg_file, args[\"k_sup\"], args[\"k_que\"])\n",
    "test_tasks = generate_tasks(test_signals, bkg_file, args[\"k_sup\"], args[\"k_que\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on the val and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, val_tasks, 200, \"Eval Val\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f5ff148e73835ca4fa28de0f0a60b6e4be9e22106b47c94548bad0fe3aa25f7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('DeepLearning': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}