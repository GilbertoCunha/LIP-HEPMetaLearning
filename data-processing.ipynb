{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = \"svg\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/wohg_hq1200.h5', 'data/hg3000_hq1000.h5', 'data/fcnc.h5', 'data/wohg_hq1400.h5', 'data/hg3000_hq1400.h5', 'data/hg3000_hq1200.h5', 'data/wohg_hq1000.h5', 'data/bkg.h5']\n"
     ]
    }
   ],
   "source": [
    "# Path of the data\n",
    "datapath = \"data\"\n",
    "\n",
    "# Files to gather\n",
    "files = glob(datapath + \"/*.h5\")\n",
    "\n",
    "# Display all available files\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_datasplit(df, filename, result_dict={}, sup_split=0.3, seed=42):\n",
    "    \"\"\"\n",
    "    A function that processes a dataframe file and returns its features, labels and weights.\n",
    "    \n",
    "    Questions: \n",
    "        - Do I have to sort dataframe initially? How so?\n",
    "        - Do I have to recalculate weights for future support and query splits?\n",
    "    \n",
    "    Data-cuts applied according to model transferability paper: https://arxiv.org/pdf/1912.04220.pdf\n",
    "        - At least 2 final state leptons\n",
    "        - At least 1 b-tagged jet\n",
    "        - Must have a large scalar sum of transverse momentum (>500GeV)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initial size\n",
    "    initial_size = len(df)\n",
    "    \n",
    "    # Apply data cuts\n",
    "    df = df[(df[\"Electron_Multi\"] + df[\"Muon_Multi\"]) > 1]\n",
    "    df = df[(df[\"Jet1_BTag\"] + df[\"Jet2_BTag\"] + df[\"Jet3_BTag\"] + df[\"Jet4_BTag\"] + df[\"Jet5_BTag\"]) > 0]\n",
    "    df = df[df[\"ScalarHT_HT\"] > 500]\n",
    "    \n",
    "    # Determine cut ratio\n",
    "    split = df[\"gen_split\"].iloc[0].capitalize()\n",
    "    cut_ratio = 100 * (initial_size - len(df)) / initial_size\n",
    "    \n",
    "    # Display cut ratio information\n",
    "    spacing = 0 if split == \"Train\" else (1 if split == \"Test\" else 2)\n",
    "    print(f\"File: {filename} | Split: {split}\" + spacing*\" \" + f\" | Drop ratio: {cut_ratio}%\")\n",
    "    \n",
    "    # Gather weights and labels\n",
    "    w = df[\"gen_weights\"].to_numpy()\n",
    "    y = df[\"gen_label\"]\n",
    "    \n",
    "    # Replace label strings with integers\n",
    "    y = y.replace({\"signal\": 1, \"bkg\": 0}).to_numpy()\n",
    "    \n",
    "    # Gather features (drop all gen collumns)\n",
    "    drop_cols = [col for col in df if \"gen\" in col]\n",
    "    columns = df.drop(columns=drop_cols).columns.to_list()\n",
    "    X = df.drop(columns=drop_cols).to_numpy()\n",
    "    \n",
    "    # Join everything in a dictionary\n",
    "    split = split.lower()\n",
    "    result_dict[split] = {} if split not in result_dict else result_dict[split]\n",
    "    result_dict[split][filename] = {\n",
    "        \"columns\": columns,\n",
    "        \"features\": X, \n",
    "        \"labels\": y, \n",
    "        \"weights\": w\n",
    "    }\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  12%|█▎        | 1/8 [00:00<00:02,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: wohg_hq1200 | Split: Train | Drop ratio: 3.191828917969997%\n",
      "File: wohg_hq1200 | Split: Val   | Drop ratio: 3.1449213769655757%\n",
      "File: wohg_hq1200 | Split: Test  | Drop ratio: 3.1729131175468486%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  25%|██▌       | 2/8 [00:00<00:02,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: hg3000_hq1000 | Split: Train | Drop ratio: 2.610543357280178%\n",
      "File: hg3000_hq1000 | Split: Val   | Drop ratio: 2.3605150214592276%\n",
      "File: hg3000_hq1000 | Split: Test  | Drop ratio: 2.3593095700132776%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  38%|███▊      | 3/8 [00:01<00:02,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: fcnc | Split: Train | Drop ratio: 0.0%\n",
      "File: fcnc | Split: Val   | Drop ratio: 0.0%\n",
      "File: fcnc | Split: Test  | Drop ratio: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  50%|█████     | 4/8 [00:01<00:01,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: wohg_hq1400 | Split: Train | Drop ratio: 2.958243258618728%\n",
      "File: wohg_hq1400 | Split: Val   | Drop ratio: 2.508591065292096%\n",
      "File: wohg_hq1400 | Split: Test  | Drop ratio: 2.8042753706470522%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  62%|██████▎   | 5/8 [00:02<00:01,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: hg3000_hq1400 | Split: Train | Drop ratio: 2.058660763696735%\n",
      "File: hg3000_hq1400 | Split: Val   | Drop ratio: 2.178649237472767%\n",
      "File: hg3000_hq1400 | Split: Test  | Drop ratio: 2.102933038184837%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  75%|███████▌  | 6/8 [00:02<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: hg3000_hq1200 | Split: Train | Drop ratio: 2.4547945205479453%\n",
      "File: hg3000_hq1200 | Split: Val   | Drop ratio: 2.3273855702094646%\n",
      "File: hg3000_hq1200 | Split: Test  | Drop ratio: 2.311624805512336%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  88%|████████▊ | 7/8 [00:02<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: wohg_hq1000 | Split: Train | Drop ratio: 3.354134165366615%\n",
      "File: wohg_hq1000 | Split: Val   | Drop ratio: 3.087629876494805%\n",
      "File: wohg_hq1000 | Split: Test  | Drop ratio: 3.8438967136150235%\n",
      "File: bkg | Split: Train | Drop ratio: 0.3194953551864649%\n",
      "File: bkg | Split: Val   | Drop ratio: 0.33745518401990193%\n",
      "File: bkg | Split: Test  | Drop ratio: 0.33878341185800254%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 8/8 [00:19<00:00,  2.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define data parameters\n",
    "data_dict = {}\n",
    "sup_split = 0.3\n",
    "random_seed = 42\n",
    "\n",
    "# Populate data dict\n",
    "for file in tqdm(files, total=len(files), desc=\"Processing data\"):\n",
    "    # Read .h5 file\n",
    "    df = pd.read_hdf(file)\n",
    "    filename = file.split(\"/\")[-1].split(\".\")[0]\n",
    "    \n",
    "    # Train, Val and Test split\n",
    "    df_train = df[df[\"gen_split\"] == \"train\"]\n",
    "    df_val = df[df[\"gen_split\"] == \"val\"]\n",
    "    df_test = df[df[\"gen_split\"] == \"test\"]\n",
    "    \n",
    "    # Insert data into dictionary\n",
    "    data_dict = df_datasplit(df_train, filename, data_dict, sup_split, random_seed)\n",
    "    data_dict = df_datasplit(df_val, filename, data_dict, sup_split, random_seed)\n",
    "    data_dict = df_datasplit(df_test, filename, data_dict, sup_split, random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: wohg_hq1200 | Number of columns: 118\n",
      "Sample: hg3000_hq1000 | Number of columns: 118\n",
      "Sample: fcnc | Number of columns: 69\n",
      "Sample: wohg_hq1400 | Number of columns: 118\n",
      "Sample: hg3000_hq1400 | Number of columns: 118\n",
      "Sample: hg3000_hq1200 | Number of columns: 118\n",
      "Sample: wohg_hq1000 | Number of columns: 118\n",
      "Sample: bkg | Number of columns: 118\n"
     ]
    }
   ],
   "source": [
    "for sample in data_dict[\"train\"]:\n",
    "    print(f\"Sample: {sample} | Number of columns: \" + str(len(data_dict[\"train\"][sample][\"columns\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(data, filename, split, axis):\n",
    "    X, w = data[split][filename][\"features\"], data[split][filename][\"weights\"]\n",
    "    \n",
    "    # Do stuff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
